name: CI/CD for Airflow & dbt

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build_and_test:
    name: Compile dbt Models
    runs-on: ubuntu-latest
    environment: production

    steps:
      # 1️⃣ Checkout Repository
      - name: Checkout Repository
        uses: actions/checkout@v4

      # 2️⃣ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      # 3️⃣ Install dbt
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dbt-bigquery

      # 4️⃣ Setup GCP Credentials
      - name: Set up GCP Credentials
        run: |
          echo "${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}" > ${{ github.workspace }}/gcp_key.json
          export GOOGLE_APPLICATION_CREDENTIALS=${{ github.workspace }}/gcp_key.json

      # 5️⃣ Run dbt build
      - name: Run dbt compile
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp_key.json
          GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          DBT_PROJECT_DIR: ${{ secrets.DBT_PROJECT_DIR }}
          DBT_PROFILES_DIR: ${{ secrets.DBT_PROFILES_DIR }}
          GCS_BUCKET: ${{ secrets.GCS_BUCKET }}
          BQ_DATASET: ${{ secrets.BQ_DATASET }}
          BQ_TABLE_ECOM_PRODUCTS: ${{ secrets.BQ_TABLE_ECOM_PRODUCTS }}
          BQ_TABLE_ECOM_CUSTOMERS_ECOM: ${{ secrets.BQ_TABLE_ECOM_CUSTOMERS_ECOM }}
          BQ_TABLE_ECOM_TRANSACTIONS: ${{ secrets.BQ_TABLE_ECOM_TRANSACTIONS }}
          BQ_TABLE_ECOM_ORDERS: ${{ secrets.BQ_TABLE_ECOM_ORDERS }}
          POSTGRES_CONN: ${{ secrets.POSTGRES_CONN }}
        run: |
          cd $DBT_PROJECT_DIR
          dbt deps
          dbt compile --profiles-dir $DBT_PROFILES_DIR -s stg_loans
        shell: bash

      # 6️⃣ Clean up credentials
      - name: Clean up Credentials
        if: always()
        run: rm -f ${{ github.workspace }}/gcp_key.json
